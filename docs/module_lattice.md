# Module Lattice Math and Code Guide

This document explains the math model behind `src/module_lattice/` and how each concept maps to the Rust code.

## Why Module Lattices (Deeper Math Intro)

Classical lattice cryptography starts from integer lattices:

- A lattice in `R^n` is `L(B) = {B z : z in Z^n}` for a full-rank basis matrix `B`.
- Security problems (SVP/CVP/SIS/LWE variants) are about finding short vectors or solving noisy linear relations.

Module-lattice cryptography keeps the same hardness flavor but changes the algebraic domain from `Z` to a polynomial ring:

- Base ring: `R = Z[X] / (X^n + 1)` with `n = 256` in ML-DSA.
- Reduced ring: `R_q = R / qR = F_q[X] / (X^n + 1)`.
- Work in modules `R_q^k` (vectors of `k` ring elements), not just vectors over `Z_q`.

Why this matters:

- **Compared with plain lattices:** structure gives faster arithmetic (especially via NTT) and smaller keys/signatures.
- **Compared with ideal lattices:** modules retain useful structure but are less rigid than rank-1 ideals, giving a conservative middle ground.

How this is still a lattice problem:

- Each polynomial in `R_q` corresponds to `n` coefficients in `F_q`.
- A vector in `R_q^k` corresponds to `n * k` coefficients.
- So module operations over polynomials induce linear-algebra constraints over high-dimensional integer/coefficient lattices.

ML-DSA uses this view in two layers at once:

- **Algebra layer:** compactly describe operations as ring/module linear algebra (`A * s`, inner products, decompositions).
- **Geometry layer:** control vector and coefficient sizes (norm bounds) so signatures are correct and leakage-resistant.

In short: module lattices are "structured high-dimensional lattices" where polynomial algebra gives efficiency, while hardness is still tied to finding short relations in large lattices.

### Lattice Geometry in One Page

Let `B in R^(n x m)` be a full-rank basis matrix with columns `b_1, ..., b_m`.

- The lattice generated by `B` is:

  `L(B) = {B z : z in Z^m} = {sum_i z_i b_i : z_i in Z}`

- Geometrically, this is an infinite periodic grid in `R^n`.
- The same lattice can have many different bases.
- "Good" bases have short, nearly orthogonal vectors; "bad" bases are long and skewed.

Norm language used by lattice problems:

- Euclidean norm: `||x||_2 = sqrt(sum_i x_i^2)`
- Infinity norm: `||x||_inf = max_i |x_i|`
- First minimum: `lambda_1(L) = min_{v in L \ {0}} ||v||_2`

`lambda_1(L)` is the length of the shortest nonzero lattice vector.

### Short Vector Problem (SVP)

Given a basis `B`, find a nonzero vector `v in L(B)` with minimal norm.

- **Exact SVP**: find `v` such that `||v||_2 = lambda_1(L)`.
- **Approximate SVP**: find `v` with `||v||_2 <= gamma * lambda_1(L)`.

Why this is hard in high dimensions:

- The search space over integer combinations is huge.
- Geometry gets increasingly complex as dimension grows.
- No known polynomial-time algorithms (classical or quantum) solve cryptographic parameter sets.

### From SVP to Short-Relation Problems (SIS)

A common cryptographic problem is SIS:

- Given `A in Z_q^(n x m)`, find `x != 0` such that

  `A x = 0 (mod q)`

- with `x` short (small `||x||`, often `||x||_inf` or `||x||_2` bounded).

This is a short-vector problem in disguise. The linear congruence defines a structured set of solutions, and the hard part is finding one that is short.

Toy SIS-style example:

- Let `q = 17`, `A = [3 5 7]` (a `1 x 3` matrix).
- Need `x = (x1, x2, x3) != 0` with

  `3x1 + 5x2 + 7x3 = 0 (mod 17)`.

- Choose small `x1 = 1`, `x2 = 2`; then

  `3 + 10 + 7x3 = 0 (mod 17)` -> `7x3 = 4 (mod 17)`.

- Since `7^{-1} = 5 (mod 17)`, `x3 = 20 = 3 (mod 17)`.
- So `x = (1, 2, 3)` is a valid short relation.

Real schemes choose dimensions and parameters so finding such short relations without trapdoor information is computationally hard.

### Module-SIS View (What ML-DSA Uses)

Module lattices replace scalar coordinates by ring elements.

- Ring: `R_q = F_q[X] / (X^n + 1)`.
- Vectors: `R_q^k`.
- Matrix equation: `A * z = 0` over `R_q`, with `z` short.

Flattening viewpoint:

- One polynomial in `R_q` -> `n` coefficients in `F_q`.
- One vector in `R_q^k` -> `n * k` coefficients.

So module equations are still large lattice equations, but with algebraic structure that enables fast transforms (NTT) and compact keys/signatures.

## 0) Toy-Size Intuition (Small Examples)

Real ML-DSA uses degree 256 and large prime `q = 8_380_417`. For intuition, use tiny numbers first.

### A) Field example (`F_17`)

- `5 + 14 = 19 = 2 (mod 17)`
- `5 - 9 = -4 = 13 (mod 17)`
- `5 * 7 = 35 = 1 (mod 17)`

This is exactly what `Elem<F>` does in code after reduction.

### B) Polynomial coefficient operations

Code stores 256 coefficients, but imagine 8 coefficients to see it clearly:

- `p = [1, 2, 0, 0, 0, 0, 0, 0]`
- `r = [3, 4, 0, 0, 0, 0, 0, 0]`

Then element-wise operations are:

- `p + r = [4, 6, 0, 0, 0, 0, 0, 0]`
- `p - r = [15, 15, 0, 0, 0, 0, 0, 0]` over `F_17`
- `3 * p = [3, 6, 0, 0, 0, 0, 0, 0]`

This matches `Polynomial<F>` `+`, `-`, and scalar `Elem<F> * Polynomial<F>`.

### C) Vector and matrix intuition

Take length-2 vectors over polynomials:

- `v = [p0, p1]`, `w = [r0, r1]`
- `v + w = [p0 + r0, p1 + r1]`

In NTT domain, dot-product style multiplication is:

- `<v_hat, w_hat> = p0_hat * r0_hat + p1_hat * r1_hat`

That is what `&NttVector * &NttVector -> NttPolynomial` computes.

### D) Encoding example (4 bits)

Pack 8 small values into 4 bytes:

- input: `[1, 2, 15, 0, 7, 3, 12, 8]`
- pack pairs: `(1,2), (15,0), (7,3), (12,8)`
- bytes: `1 + (2 << 4) = 33`, `15 + (0 << 4) = 15`, `7 + (3 << 4) = 55`, `12 + (8 << 4) = 140`
- encoded: `[33, 15, 55, 140]`

Decode does mask/shift and gets the original values back.

Use this mental model, then scale up to 256 coefficients and scheme parameter sizes.

## 1) Algebraic Objects Used by ML-DSA

ML-DSA works over a prime field and polynomial modules.

- Prime field:

  `F_q = Z / qZ`

- Polynomial ring used by the scheme:

  `R_q = F_q[X] / (X^256 + 1)`

- Vector and matrix modules:

  - `R_q^k` (vectors of `k` polynomials)
  - `R_q^(k x l)` (matrices of polynomials)

In this crate, the shared module-lattice layer mostly defines linear operations on coefficients/vectors and NTT-domain containers. Scheme-specific polynomial multiplication rules are provided downstream.

## 2) Field Arithmetic (`algebra.rs`)

### 2.1) The Prime Field F_q

A **prime field** `F_q` is the set `{0, 1, ..., q-1}` with addition and multiplication performed modulo `q`. For ML-DSA:

```
q = 8_380_417 = 2^23 - 2^13 + 1
```

This particular prime was chosen because:

1. **NTT-friendly**: `q ≡ 1 (mod 2·256)`, meaning 512th roots of unity exist in `F_q`, enabling the degree-256 NTT.
2. **Fits in 23 bits**: All field elements fit in a `u32` with room for lazy reduction.
3. **Special form**: The `2^23 - 2^13 + 1` structure allows efficient reduction.

Every nonzero element has a multiplicative inverse (since `q` is prime), making `F_q` a field. The code does not compute general inverses; it only needs addition, subtraction, multiplication, and negation.

### 2.2) Field Trait and `define_field!` Macro

The `Field` trait (`module_lattice/algebra.rs:12`) abstracts over the prime modulus and its associated integer types:

```
Field {
    Int      — primary representation (u32 for ML-DSA)
    Long     — double-width for products (u64)
    LongLong — quadruple-width for Barrett (u128)
    Q        — the prime modulus
}
```

The `define_field!` macro generates a zero-sized struct implementing `Field`. It auto-computes Barrett constants at compile time:

```
BARRETT_SHIFT = 2 * (floor(log2(Q)) + 1)
BARRETT_MULTIPLIER = floor(2^BARRETT_SHIFT / Q)
```

For `Q = 8_380_417`: `floor(log2(Q)) + 1 = 23`, so `BARRETT_SHIFT = 46` and `BARRETT_MULTIPLIER = floor(2^46 / 8_380_417) = 8_396_807_267_637`.

### 2.3) Element Operations

For `a, b ∈ F_q`, `Elem<F>` implements:

| Operation | Formula | Reduction method |
|-----------|---------|-----------------|
| `a + b` | `small_reduce(a + b)` | Conditional subtraction (result < 2q) |
| `a - b` | `small_reduce(a + q - b)` | Conditional subtraction (result < 2q) |
| `-a` | `small_reduce(q - a)` | Conditional subtraction |
| `a * b` | `barrett_reduce(a * b)` | Barrett reduction (product < q²) |

**Why different reductions?** Addition and subtraction produce results bounded by `2q - 1`, so a single comparison suffices. Multiplication produces results up to `(q-1)² ≈ 2^46`, requiring the more expensive Barrett method.

### 2.4) Barrett Reduction — Full Derivation

**Goal**: Compute `x mod q` without division.

**Key identity**: For any integer `x ≥ 0`,

```
x mod q = x - floor(x / q) · q
```

Division by `q` is expensive. Barrett's trick replaces it with multiplication and bit-shift:

1. **Precompute** `m = floor(2^k / q)` where `k = BARRETT_SHIFT`.
2. **Approximate** `floor(x / q) ≈ floor(x · m / 2^k)` — this replaces division by `q` with multiplication by `m` followed by a right shift.
3. **Compute remainder** `r = x - floor(x · m / 2^k) · q`.
4. **Correct** if `r ≥ q`, subtract `q` once (the approximation undershoots by at most 1).

**Why the approximation works**: We have `m = floor(2^k / q)`, so:

```
2^k / q - 1 < m ≤ 2^k / q
```

Therefore:

```
x / q - x / 2^k ≤ x · m / 2^k ≤ x / q
```

The error is at most `x / 2^k`. For `x < q²` and `k = 2 · ceil(log2(q))`, this error is less than 1, guaranteeing the approximation is exact or off by 1.

**In code** (`algebra.rs:90-97`):

```rust
fn barrett_reduce(x: Self::Long) -> Self::Int {
    let x: Self::LongLong = x.into();           // widen to 128 bits
    let product = x * Self::BARRETT_MULTIPLIER;  // x · m
    let quotient = product >> Self::BARRETT_SHIFT; // floor(x·m / 2^k)
    let remainder = x - quotient * Self::QLL;    // x - approx_quotient · q
    Self::small_reduce(Truncate::truncate(remainder)) // final correction
}
```

### 2.5) Barrett Reduction for Arbitrary Moduli

The scheme-level code (`src/algebra.rs`) extends Barrett reduction to moduli other than `q`. The `BarrettReduce` trait works for any compile-time `Unsigned` type `M`:

```
M::reduce(x) computes x mod M for x < M²
```

This is used for centered modular reduction with `2γ₂` and `2^d` as moduli.

### 2.6) Constant-Time Division

Hardware `DIV` instructions have data-dependent timing on most architectures, creating a side-channel risk. The `ConstantTimeDiv` trait replaces `x / M` with:

```
ct_div(x) = floor(x · ceil(2^48 / M) / 2^48)
```

Using ceiling division for the multiplier ensures we never underestimate the quotient. The shift of 48 provides sufficient precision for all ML-DSA operands (which are bounded by `q < 2^24`).

## 3) The Polynomial Ring R_q

### 3.1) Definition

```
R_q = F_q[X] / (X^256 + 1)
```

Elements of `R_q` are polynomials of degree at most 255 with coefficients in `F_q`. The quotient by `(X^256 + 1)` means:

- `X^256 ≡ -1 (mod X^256 + 1)`
- `X^257 ≡ -X`, `X^512 ≡ 1`, etc.

This makes `R_q` a **ring** (not a field) — it has zero divisors in general, but for cryptographic purposes the relevant property is that finding short vectors in lattices over `R_q` is computationally hard.

### 3.2) Why X^256 + 1?

The polynomial `X^256 + 1` is the 512th **cyclotomic polynomial** `Φ_512(X)`. It is irreducible over `Z`, which gives `R_q` nice algebraic properties:

1. **Negacyclic structure**: Multiplication by `X` in `R_q` cyclically shifts coefficients and negates the wrap-around term. This is the foundation of the NTT.
2. **Power-of-two degree**: Enables the radix-2 Cooley-Tukey butterfly structure in the NTT.
3. **Security**: The Ring-LWE and Module-LWE problems over cyclotomic rings have well-studied hardness reductions.

### 3.3) Polynomial Operations in Code

`Polynomial<F>` stores 256 coefficients as `Array<Elem<F>, U256>`. All operations are **coefficient-wise** (no polynomial multiplication is defined at this layer):

```
(f + g)_i = f_i + g_i    (mod q)
(f - g)_i = f_i - g_i    (mod q)
(c · f)_i = c · f_i      (mod q)   for scalar c ∈ F_q
```

Polynomial multiplication in `R_q` is **not** coefficient-wise — it requires convolution with negacyclic wrap-around. This is why the NTT exists: it transforms polynomials into a domain where multiplication becomes pointwise.

## 4) The Number Theoretic Transform (NTT)

### 4.1) Mathematical Foundation

The NTT is the finite-field analogue of the Discrete Fourier Transform. For ML-DSA, it exploits the factorization of `X^256 + 1` over `F_q`.

Since `q ≡ 1 (mod 512)`, there exists a primitive 512th root of unity `ζ ∈ F_q` such that `ζ^512 = 1` and `ζ^k ≠ 1` for `0 < k < 512`. For ML-DSA:

```
ζ = 1753
```

The polynomial `X^256 + 1` splits completely over `F_q` into 256 linear factors:

```
X^256 + 1 = ∏_{i=0}^{255} (X - ζ^(2·BitRev₈(i)+1))
```

where `BitRev₈` reverses the 8 bits of an index. This gives an isomorphism:

```
NTT: R_q → F_q^256
f(X) ↦ (f(ζ^(2·BitRev₈(0)+1)), f(ζ^(2·BitRev₈(1)+1)), ..., f(ζ^(2·BitRev₈(255)+1)))
```

In the NTT domain (denoted `T_q` in the code), polynomial multiplication becomes **pointwise**:

```
NTT(f · g) = NTT(f) ⊙ NTT(g)
```

where `⊙` denotes component-wise multiplication.

### 4.2) The Butterfly Structure

The NTT is computed via 8 layers of **Cooley-Tukey butterflies**. Each layer halves the sub-problem size:

**Forward butterfly** (for indices `j` and `j + len`):

```
t       = ζ^m · w[j + len]
w[j + len] = w[j] - t
w[j]       = w[j] + t
```

**Inverse butterfly** (for indices `j` and `j + len`):

```
t          = w[j]
w[j]       = t + w[j + len]
w[j + len] = (-ζ^m) · (t - w[j + len])
```

The 8 layers process sub-arrays of lengths 128, 64, 32, 16, 8, 4, 2, 1 (forward) or 1, 2, 4, 8, 16, 32, 64, 128 (inverse).

In code (`ntt.rs:72-83`), each layer is a const-generic function `ntt_layer<LEN, ITERATIONS>` where:
- `LEN` = butterfly half-width
- `ITERATIONS` = number of independent butterfly groups
- `LEN × ITERATIONS = 128` always (covering all 256 elements)

### 4.3) Bit-Reversed Zeta Table

The twiddle factors `ζ^m` are accessed in **bit-reversed order**. The precomputed table (`ntt.rs:28-54`):

```
ZETA_POW_BITREV[i] = ζ^(BitRev₈(i))   for i = 1, ..., 255
ZETA_POW_BITREV[0] = 0                  (unused sentinel)
```

This ordering matches the access pattern of the Cooley-Tukey algorithm: layer `l` uses entries `2^l, ..., 2^(l+1) - 1` of the table, and the bit-reversal ensures each entry is the correct root of unity for its butterfly.

First few values (matching FIPS 204 Appendix B):

```
ZETA_POW_BITREV[1] = ζ^128 = 4_808_194
ZETA_POW_BITREV[2] = ζ^64  = 3_765_607
ZETA_POW_BITREV[3] = ζ^192 = 3_761_513
```

### 4.4) Inverse NTT and the Scaling Factor

The inverse NTT reverses the butterfly layers and negates the twiddle factors. After all 8 layers, the result must be scaled by `n^{-1} = 256^{-1} mod q`:

```
256^{-1} mod 8_380_417 = 8_347_681
```

Verification: `256 · 8_347_681 = 2_137_006_336 = 255 · 8_380_417 + 1 ≡ 1 (mod q)`.

In code (`ntt.rs:159`): `INVERSE_256 * &Polynomial::new(w.into())` scales every coefficient.

### 4.5) NTT Multiplication (Algorithm 45)

For ML-DSA, the NTT decomposes `R_q` into 256 copies of `F_q` (degree-1 factors). Therefore NTT multiplication is simply **pointwise**:

```
(f̂ · ĝ)_i = f̂_i · ĝ_i    for i = 0, ..., 255
```

This is implemented by `MultiplyNtt for BaseField` (`ntt.rs:190-200`). The `MultiplyNtt` trait is a hook because other schemes (e.g., ML-KEM) use a different NTT variant where `X^256 + 1` factors into degree-2 polynomials, requiring paired multiplication.

### 4.6) Complexity

- **Naive polynomial multiplication** in `R_q`: `O(n²)` = 65,536 multiplications
- **NTT-based multiplication**: `O(n log n)` = 3 × NTT (forward, forward, inverse) + 256 pointwise = ~6,400 operations
- **Speedup**: ~10× for `n = 256`

### 4.7) Homomorphism Properties

The NTT is a **ring homomorphism**:

```
NTT(f + g) = NTT(f) + NTT(g)     (addition homomorphism)
NTT(f · g) = NTT(f) ⊙ NTT(g)     (multiplication homomorphism)
NTT(NTT⁻¹(f̂)) = f̂                (round-trip)
```

These properties are verified by tests in `ntt.rs:256-291`.

## 5) Module Lattices

### 5.1) Vectors over R_q

A **module vector** `v ∈ R_q^k` is a tuple of `k` polynomials:

```
v = (v_0, v_1, ..., v_{k-1})    where each v_i ∈ R_q
```

Operations are component-wise:

```
(v + w)_i = v_i + w_i
(c · v)_i = c · v_i     for scalar c ∈ F_q
```

The **inner product** of two vectors produces a single polynomial:

```
⟨v, w⟩ = Σ_{i=0}^{k-1} v_i · w_i ∈ R_q
```

In the NTT domain, this becomes:

```
⟨v̂, ŵ⟩ = Σ_{i=0}^{k-1} v̂_i ⊙ ŵ_i
```

Code (`algebra.rs:447-460`): `&NttVector * &NttVector` computes this as a fold over pointwise products.

### 5.2) Matrices over R_q

A **module matrix** `A ∈ R_q^{k×l}` has `k` rows and `l` columns, each entry being a polynomial. Matrix-vector multiplication:

```
(A · v)_i = Σ_{j=0}^{l-1} A_{i,j} · v_j = ⟨row_i(A), v⟩
```

Code (`algebra.rs:476-485`): `&NttMatrix * &NttVector` maps each row's dot product.

### 5.3) What is a Module Lattice?

A **lattice** is a discrete additive subgroup of `R^n`. A **module lattice** generalizes this to modules over polynomial rings. In ML-DSA, the public key defines a lattice:

```
L_A = { v ∈ R_q^k : v = A · s  for some s ∈ R_q^l }
```

The security of ML-DSA rests on the **Module Learning With Errors (M-LWE)** problem: given `A` and `t = A·s₁ + s₂` where `s₁, s₂` have small coefficients, it is computationally hard to recover `s₁, s₂`.

The "module" qualifier (vs. plain "lattice") means the lattice has additional algebraic structure from the ring `R_q`, which enables more compact keys and signatures compared to unstructured lattice schemes.

## 6) Decomposition Algorithms

### 6.1) Centered Modular Reduction (mod±)

For modulus `M`, the centered reduction maps `r ∈ {0, ..., q-1}` to the representative in `(-M/2, M/2]`:

```
r mod± M = r mod M           if (r mod M) ≤ M/2
           (r mod M) - M      otherwise
```

The result is stored as an element of `F_q` using the convention that negative values are represented as `q + x` (where `x < 0`). This works because `q ≫ M` for all moduli used in ML-DSA.

Code (`algebra.rs:169-176`): `mod_plus_minus` uses `BarrettReduce` for the initial reduction, then conditionally subtracts `M`.

### 6.2) Power2Round (Algorithm 35)

Splits `r ∈ F_q` into high and low parts relative to `2^d` (where `d = 13`):

```
r₀ = r mod± 2^d          (low d bits, centered)
r₁ = (r - r₀) / 2^d      (remaining high bits)
```

Reconstruction: `r = r₁ · 2^d + r₀`.

This is used in key generation to split `t = A·s₁ + s₂` into `t₁` (stored in public key, 10 bits) and `t₀` (stored in secret key, 13 bits).

### 6.3) Decompose (Algorithm 36)

Generalizes Power2Round to arbitrary modulus `2γ₂`:

```
r₀ = r mod± 2γ₂
r₁ = (r - r₀) / 2γ₂
```

Special case: when `r - r₀ = q - 1` (which would make `r₁` non-integral), set `r₁ = 0` and `r₀ = r₀ - 1`.

The constant-time division `(r - r₀) / 2γ₂` uses `ConstantTimeDiv` to avoid timing leaks.

ML-DSA parameter sets use:
- **ML-DSA-44**: `γ₂ = (q-1)/88 = 95_232`, so `2γ₂ = 190_464`
- **ML-DSA-65/87**: `γ₂ = (q-1)/32 = 261_888`, so `2γ₂ = 523_776`

### 6.4) HighBits and LowBits (Algorithms 37-38)

These are simply the two components of `Decompose`:

```
HighBits(r) = Decompose(r).0 = r₁
LowBits(r)  = Decompose(r).1 = r₀
```

Used during signing to check whether a candidate signature's low-order bits are small enough (the rejection sampling loop).

### 6.5) Infinity Norm

For `w ∈ F_q`, the infinity norm uses the centered representation:

```
‖w‖_∞ = |w mod± q| = min(w, q - w)
```

Extended to polynomials and vectors by taking the maximum over all coefficients:

```
‖f‖_∞ = max_i |f_i mod± q|
‖v‖_∞ = max_j ‖v_j‖_∞
```

This is the key metric in ML-DSA's rejection sampling: a signature candidate `z` is accepted only if `‖z‖_∞ < γ₁ - β`.

## 7) Polynomial, Vector, NTT Types (`algebra.rs`)

Main containers:

| Math object | Code type | Storage |
|-------------|-----------|---------|
| `a ∈ F_q` | `Elem<F>` | Single `F::Int` |
| `f ∈ R_q` (coefficient) | `Polynomial<F>` | `Array<Elem<F>, U256>` |
| `v ∈ R_q^k` | `Vector<F, K>` | `Array<Polynomial<F>, K>` |
| `f̂ ∈ T_q` (NTT domain) | `NttPolynomial<F>` | `Array<Elem<F>, U256>` |
| `v̂ ∈ T_q^k` | `NttVector<F, K>` | `Array<NttPolynomial<F>, K>` |
| ` ∈ T_q^{k×l}` | `NttMatrix<F, K, L>` | `Array<NttVector<F, L>, K>` |

Supported operations include:

- element-wise `+`, `-`, unary `-`
- scalar multiplication by `Elem<F>`
- NTT-domain vector dot products and matrix-vector products

`MultiplyNtt` is intentionally a trait hook. The concrete NTT multiply rule is scheme-specific and implemented in higher-level modules.

## 8) Bit Packing and Unpacking (`encode.rs`)

### 8.1) The Encoding Problem

A polynomial has 256 coefficients, each requiring `d` bits. The goal is to pack them into exactly `256 · d / 8 = 32d` bytes with no wasted space.

### 8.2) The Algorithm

For bit width `d`, the encoding processes coefficients in groups. The group size depends on `gcd(d, 8)`:

```
EncodingUnit = lcm(d, 8) = d · 8 / gcd(d, 8)
ValueStep    = EncodingUnit / d    (coefficients per group)
ByteStep     = EncodingUnit / 8    (bytes per group)
```

For example:
- `d = 4`: `ValueStep = 2`, `ByteStep = 1` (pack 2 values into 1 byte)
- `d = 10`: `ValueStep = 4`, `ByteStep = 5` (pack 4 values into 5 bytes)
- `d = 13`: `ValueStep = 8`, `ByteStep = 13` (pack 8 values into 13 bytes)

**Encoding** (per group):

```
x = Σ_{j=0}^{ValueStep-1} v_j · 2^(d·j)
emit x as ByteStep little-endian bytes
```

**Decoding** (per group):

```
read ByteStep bytes as little-endian integer x
v_j = (x >> (d·j)) & (2^d - 1)
```

### 8.3) Type-Level Size Enforcement

The `typenum` crate computes all sizes at compile time:

```
EncodedPolynomialSize<D> = D × 32     (bytes per polynomial)
EncodedVectorSize<D, K>  = D × 32 × K (bytes per vector)
```

The type system enforces:
- `Prod<D, U32>: ArraySize` — polynomial encoding size is valid
- `Prod<EncodedPolynomialSize, K>: ArraySize` — vector encoding size is valid
- `Rem<K, Output = U0>` — vector size divides evenly for unflattening

This means encoding size mismatches are caught at compile time, not runtime.

### 8.4) Round-Trip Guarantee

For any polynomial `f` with coefficients in `[0, 2^d)`:

```
decode(encode(f)) = f
```

This is the fundamental correctness property relied on by ML-DSA key and signature serialization.

## 9) Utilities (`util.rs`)

### 9.1) Truncate

`Truncate<T>` safely extracts the low bits when converting between integer widths:

```
u32::truncate(x: u128) = x & 0xFFFF_FFFF
u32::truncate(x: u64)  = x & 0xFFFF_FFFF
```

Used after Barrett reduction to narrow the remainder back to the field's `Int` type.

### 9.2) Flatten / Unflatten

These convert between nested and flat array representations:

```
Flatten:   [[T; M]; N] → [T; M·N]
Unflatten: [T; M·N] → [[T; M]; N]
```

The implementation uses pointer casts, which are safe because Rust guarantees `[[T; M]; N]` and `[T; M·N]` have identical memory layouts. A reference variant of `Unflatten` avoids copying when only read access is needed.

These are used by vector encoding: a `Vector<K>` is encoded as `K` separate polynomial encodings, then flattened into a single byte array.

## 10) Quick Mapping: Math → Code

| Mathematical object | Code type | File |
|---|---|---|
| `F_q` element | `Elem<F>` | `module_lattice/algebra.rs` |
| polynomial in `R_q` (coefficient view) | `Polynomial<F>` | `module_lattice/algebra.rs` |
| module vector `R_q^k` | `Vector<F, K>` | `module_lattice/algebra.rs` |
| NTT-domain polynomial | `NttPolynomial<F>` | `module_lattice/algebra.rs` |
| NTT-domain module matrix | `NttMatrix<F, K, L>` | `module_lattice/algebra.rs` |
| bit-pack / bit-unpack | `Encode<D>::encode` / `decode` | `module_lattice/encode.rs` |
| Barrett reduction | `Field::barrett_reduce` | `module_lattice/algebra.rs` |
| Forward NTT | `Ntt::ntt` | `ntt.rs` |
| Inverse NTT | `NttInverse::ntt_inverse` | `ntt.rs` |
| Pointwise NTT multiply | `MultiplyNtt::multiply_ntt` | `ntt.rs` |
| Decompose | `Decompose::decompose` | `algebra.rs` |
| Power2Round | `AlgebraExt::power2round` | `algebra.rs` |
| HighBits / LowBits | `AlgebraExt::high_bits` / `low_bits` | `algebra.rs` |
| Centered mod | `AlgebraExt::mod_plus_minus` | `algebra.rs` |
| Infinity norm | `AlgebraExt::infinity_norm` | `algebra.rs` |

## 11) Minimal Usage Example

```rust
use crate::define_field;
use crate::module_lattice::algebra::{Elem, Polynomial};
use crate::module_lattice::encode::Encode;
use hybrid_array::typenum::U4;

define_field!(TestField, u32, u64, u128, 17);

let mut coeffs = hybrid_array::Array::default();
coeffs[0] = Elem::<TestField>::new(1);
coeffs[1] = Elem::<TestField>::new(2);
let p = Polynomial::new(coeffs);

let enc = Encode::<U4>::encode(&p);
let dec: Polynomial<TestField> = Encode::<U4>::decode(&enc);
assert_eq!(p, dec);
```

This mirrors the round-trip property relied on by ML-DSA key/signature encodings.
